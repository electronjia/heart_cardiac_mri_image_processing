{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "from scipy.ndimage import distance_transform_edt, gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu, sobel\n",
    "from skimage.measure import label, regionprops, marching_cubes, mesh_surface_area\n",
    "from skimage.segmentation import clear_border, watershed\n",
    "from skimage.morphology import remove_small_objects, binary_opening, binary_closing, disk\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from scipy.spatial import Delaunay\n",
    "from skimage.io import imsave\n",
    "import pandas as pd\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydicom\n",
    "# pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DICOM series: 200 slices\n",
      "Volume shape: (200, 256, 256)\n",
      "Voxel spacing: (8.0, 1.367188, 1.367187)\n"
     ]
    }
   ],
   "source": [
    "def load_dicom_series(folder_path):\n",
    "    \"\"\"\n",
    "    Load a DICOM image series from a folder and return the 3D volume and voxel spacing.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder containing DICOM files.\n",
    "\n",
    "    Returns:\n",
    "    - volume (numpy array): 3D NumPy array of image data.\n",
    "    - spacing (tuple): (slice thickness, pixel spacing in x, pixel spacing in y).\n",
    "    \"\"\"\n",
    "    dicom_files = []\n",
    "\n",
    "    # Load DICOM files from folder\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.dcm'):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                dicom_files.append(pydicom.dcmread(filepath))\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Warning: Could not read {filename} - {e}\")\n",
    "\n",
    "    if not dicom_files:\n",
    "        raise ValueError(\"❌ No valid DICOM files found in the folder.\")\n",
    "\n",
    "    # Try sorting by ImagePositionPatient if available\n",
    "    try:\n",
    "        dicom_files.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
    "    except AttributeError:\n",
    "        print(\"⚠️ ImagePositionPatient not found. Using default order.\")\n",
    "\n",
    "    # Stack images into a 3D NumPy array\n",
    "    volume = np.stack([file.pixel_array for file in dicom_files])\n",
    "\n",
    "    # Extract voxel spacing\n",
    "    try:\n",
    "        slice_thickness = float(dicom_files[0].SliceThickness)\n",
    "    except AttributeError:\n",
    "        slice_thickness = 1.0  # Default value if missing\n",
    "        print(\"⚠️ SliceThickness not found. Using default value of 1.0.\")\n",
    "\n",
    "    try:\n",
    "        pixel_spacing = dicom_files[0].PixelSpacing\n",
    "        spacing = (slice_thickness, float(pixel_spacing[0]), float(pixel_spacing[1]))\n",
    "    except AttributeError:\n",
    "        spacing = (slice_thickness, 1.0, 1.0)  # Default pixel spacing\n",
    "        print(\"⚠️ PixelSpacing not found. Using default (1.0, 1.0).\")\n",
    "\n",
    "    print(f\"Loaded DICOM series: {len(dicom_files)} slices\")\n",
    "    print(f\"Volume shape: {volume.shape}\")\n",
    "    print(f\"Voxel spacing: {spacing}\")\n",
    "\n",
    "    return volume, spacing, dicom_files\n",
    "\n",
    "# Example usage for patient SCD0000101\n",
    "# folder_path = r\"C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_01\\SCD0000101\\CINESAX_300\" # Change depending on where you patient files are\n",
    "# folder_path = r\"C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_05\\SCD0004501\\CINESAX_1100\"\n",
    "# folder_path = r\"C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_05\\SCD0004201\\CINESAX_302\"\n",
    "# folder_path = r\"C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\"\n",
    "\n",
    "folder_path = r\"C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_03\\SCD0002701\\CINESAX_1000\"\n",
    "\n",
    "volume, spacing, dicom_files = load_dicom_series(folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_volume(volume):\n",
    "    # Clip out extreme values (optional, helps with outliers)\n",
    "    volume = np.clip(volume, np.percentile(volume, 1), np.percentile(volume, 99))\n",
    "\n",
    "    # Min-max normalization to [0, 1]\n",
    "    volume = volume.astype(np.float32)\n",
    "    volume -= volume.min()\n",
    "    volume /= volume.max()\n",
    "\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_center_weighting(volume, alpha=1):\n",
    "    \"\"\"\n",
    "    Enhance the image intensity towards the center using a Gaussian weight map.\n",
    "\n",
    "    Parameters:\n",
    "    - volume: 3D MRI volume.\n",
    "    - alpha: Weighting factor (0.0 - 1.0).\n",
    "    \"\"\"\n",
    "    z, y, x = volume.shape\n",
    "\n",
    "    # Create a Gaussian weight map centered in the middle\n",
    "    yy, xx = np.meshgrid(np.linspace(-1, 1, x), np.linspace(-1, 1, y))\n",
    "    distance = np.sqrt(xx**2 + yy**2)\n",
    "    weight_map = np.exp(-4 * distance**2)  # Gaussian-like falloff\n",
    "\n",
    "    weighted_volume = np.zeros_like(volume)\n",
    "\n",
    "    # Apply the weight map to each slice\n",
    "    for i in range(z):\n",
    "        weighted_volume[i] = volume[i] * (1 + alpha * weight_map)\n",
    "\n",
    "    return weighted_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(volume, crop_size):\n",
    "    \"\"\"\n",
    "    Crop the center region of a 3D volume.\n",
    "\n",
    "    Parameters:\n",
    "    - volume: 3D NumPy array (z, y, x).\n",
    "    - crop_size: Tuple (crop_height, crop_width).\n",
    "\n",
    "    Returns:\n",
    "    - Cropped volume.\n",
    "    \"\"\"\n",
    "    z, y, x = volume.shape\n",
    "    crop_height, crop_width = crop_size\n",
    "\n",
    "    # Calculate center coordinates\n",
    "    center_y, center_x = y // 2, x // 2\n",
    "\n",
    "    # Define cropping boundaries\n",
    "    y_min = max(center_y - crop_height // 2, 0)\n",
    "    y_max = min(center_y + crop_height // 2, y)\n",
    "    x_min = max(center_x - crop_width // 2, 0)\n",
    "    x_max = min(center_x + crop_width // 2, x)\n",
    "\n",
    "    # Crop the volume\n",
    "    cropped_volume = volume[:, y_min:y_max, x_min:x_max]\n",
    "\n",
    "    return cropped_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_border_components(binary_slice):\n",
    "    \"\"\"\n",
    "    Remove connected components touching the borders of the image.\n",
    "\n",
    "    Parameters:\n",
    "    - binary_slice (numpy array): A 2D binary image.\n",
    "\n",
    "    Returns:\n",
    "    - cleaned_slice (numpy array): Binary image with border-touching components removed.\n",
    "    \"\"\"\n",
    "    # Label connected components in the binary mask\n",
    "    labeled_slice = label(binary_slice)\n",
    "\n",
    "    # Remove components touching the image borders\n",
    "    cleaned_slice = clear_border(labeled_slice)\n",
    "\n",
    "    # Convert back to binary\n",
    "    return cleaned_slice > 0\n",
    "\n",
    "def segment_heart_otsu(volume):\n",
    "    \"\"\"\n",
    "    Segment the heart using Otsu's thresholding and remove border-touching components.\n",
    "\n",
    "    Steps:\n",
    "    1. Apply Otsu's thresholding to segment potential heart regions.\n",
    "    2. Remove any connected components touching the image borders.\n",
    "    3. Return the cleaned segmented volume.\n",
    "\n",
    "    Parameters:\n",
    "    - volume (numpy array): 3D NumPy array containing the image stack.\n",
    "\n",
    "    Returns:\n",
    "    - segmented_volume (numpy array): Binary volume with only the heart region.\n",
    "    \"\"\"\n",
    "\n",
    "    segmented_volume = np.zeros_like(volume, dtype=bool)  # Initialize output\n",
    "\n",
    "    for i in range(volume.shape[0]):  # Iterate over slices\n",
    "        slice_img = volume[i]\n",
    "\n",
    "        # Step 1: Apply Otsu’s thresholding\n",
    "        thresh = threshold_otsu(slice_img)\n",
    "        binary_slice = slice_img > thresh  # Convert to binary mask\n",
    "\n",
    "        # Step 2: Remove border-touching components\n",
    "        cleaned_slice = remove_border_components(binary_slice)\n",
    "\n",
    "        # Store in output volume\n",
    "        segmented_volume[i] = cleaned_slice\n",
    "\n",
    "    return segmented_volume.astype(np.uint8)  # Convert to uint8 for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_circular_regions(segmented_volume, circularity_thresh=0.1, min_size=30):\n",
    "    \"\"\"\n",
    "    Keep only circular regions in a segmented 3D volume.\n",
    "\n",
    "    Parameters:\n",
    "    - segmented_volume: 3D binary NumPy array (segmentation mask).\n",
    "    - circularity_thresh: Circularity threshold (higher = more circular).\n",
    "    - min_size: Minimum region size to keep (removes small noise).\n",
    "\n",
    "    Returns:\n",
    "    - Filtered 3D binary mask with mostly circular regions.\n",
    "    \"\"\"\n",
    "    filtered_volume = np.zeros_like(segmented_volume)\n",
    "\n",
    "    for z in range(segmented_volume.shape[0]):\n",
    "        slice_mask = segmented_volume[z]\n",
    "\n",
    "        # Label connected components\n",
    "        labeled_mask = label(slice_mask)\n",
    "\n",
    "        for region in regionprops(labeled_mask):\n",
    "            # Calculate circularity: (4 * pi * area) / perimeter^2\n",
    "            if region.perimeter > 0:  # Avoid division by zero\n",
    "                circularity = (4 * np.pi * region.area) / (region.perimeter ** 2)\n",
    "\n",
    "                # Keep region if circular enough and above min size\n",
    "                if circularity >= circularity_thresh and region.area >= min_size:\n",
    "                    filtered_volume[z][labeled_mask == region.label] = 1\n",
    "\n",
    "    return filtered_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_watershed(segmented_volume, blur_sigma=2, distance_exp=0.7, seed_quantile=0.65):\n",
    "    \"\"\"\n",
    "    Applies an improved Watershed segmentation across all slices in a 3D volume.\n",
    "    - Uses Gaussian-blurred Sobel for smoother edge detection.\n",
    "    - Enhances distance map contrast for better LV separation.\n",
    "    - Adapts seed selection to account for intensity variations.\n",
    "\n",
    "    Parameters:\n",
    "    - segmented_volume (ndarray): Binary 3D array from Otsu thresholding.\n",
    "    - blur_sigma (float): Standard deviation for Gaussian blur (default: 1.5).\n",
    "    - distance_exp (float): Exponent for distance transform enhancement (default: 1.2).\n",
    "    - seed_quantile (float): Quantile threshold for selecting seeds (default: 0.5).\n",
    "\n",
    "    Returns:\n",
    "    - watershed_labels (ndarray): 3D array with labeled regions after Watershed segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize output volume\n",
    "    watershed_labels = np.zeros_like(segmented_volume, dtype=np.int32)\n",
    "\n",
    "    for i in range(segmented_volume.shape[0]):  # Process each slice\n",
    "        binary_slice = segmented_volume[i]\n",
    "\n",
    "        if np.sum(binary_slice) == 0:\n",
    "            continue  # Skip empty slices\n",
    "\n",
    "        # Step 1: Apply Gaussian blur to smooth noise before Sobel\n",
    "        smoothed_slice = gaussian_filter(binary_slice.astype(float), sigma=blur_sigma)\n",
    "\n",
    "        # Step 2: Compute edges using Sobel on the smoothed image\n",
    "        edges = sobel(smoothed_slice)\n",
    "\n",
    "        # Step 3: Compute the distance transform (inner areas have higher values)\n",
    "        distance_map = distance_transform_edt(binary_slice)\n",
    "\n",
    "        # Step 4: Enhance distance contrast for better watershed performance\n",
    "        distance_map = distance_map ** distance_exp\n",
    "\n",
    "        # Step 5: Adapt seed threshold based on the intensity distribution\n",
    "        seed_threshold = np.quantile(distance_map[distance_map > 0], seed_quantile)\n",
    "        seeds = distance_map > seed_threshold\n",
    "\n",
    "        # Step 6: Label connected components in the seed map\n",
    "        markers = label(seeds)\n",
    "\n",
    "        # Step 7: Apply Watershed with edges as the barrier\n",
    "        ws_result = watershed(edges, markers, mask=binary_slice)\n",
    "\n",
    "        # Store result\n",
    "        watershed_labels[i] = ws_result\n",
    "\n",
    "    return watershed_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LV_isolation(watershed_labels, min_size=50, max_size=4000, \n",
    "                 min_size_reference=400, slice_range=(41, 100), \n",
    "                 sample_slices=4):\n",
    "    \"\"\"\n",
    "    Identifies the Left Ventricle (LV) in a reference slice and extends segmentation\n",
    "    by selecting the region in each slice that has both:\n",
    "      1. The highest proportion of pixel overlap with the reference LV region.\n",
    "      2. The closest centroid distance to the reference LV region.\n",
    "      3. For slices below the reference, regions 1.5x or larger than the reference LV are ignored.\n",
    "\n",
    "    Parameters:\n",
    "    - watershed_labels (ndarray): 3D labeled array from segmentation.\n",
    "    - min_size (int): Global minimum allowable region size.\n",
    "    - max_size (int): Global maximum allowable region size.\n",
    "    - min_size_reference (int): Minimum size for selecting the reference LV region.\n",
    "    - slice_range (tuple): Range of slices to search for the reference LV.\n",
    "    - sample_slices (int): Number of slices to sample within slice_range.\n",
    "    - visualize (bool): If True, displays the chosen LV region.\n",
    "\n",
    "    Returns:\n",
    "    - lv_volume (ndarray): 3D binary array containing only the LV segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    lv_volume = np.zeros_like(watershed_labels, dtype=np.uint8)\n",
    "    num_slices = watershed_labels.shape[0]\n",
    "\n",
    "    # Step 1: Identify LV in a well-segmented reference slice\n",
    "    lower_half_slices = np.linspace(slice_range[0], slice_range[1], sample_slices, dtype=int)\n",
    "    best_lv_centroid = None\n",
    "    best_lv_label = None\n",
    "    chosen_slice = None\n",
    "    reference_lv_size = None  # Store reference LV size\n",
    "\n",
    "    for i in lower_half_slices:\n",
    "        slice_labels = label(watershed_labels[i])\n",
    "        if np.max(slice_labels) == 0:\n",
    "            continue  # Skip empty slices\n",
    "\n",
    "        # Apply reference slice threshold\n",
    "        regions = [r for r in regionprops(slice_labels) if min_size_reference <= r.area <= max_size]\n",
    "\n",
    "        if not regions:\n",
    "            continue\n",
    "\n",
    "        # Find the most circular LV region\n",
    "        most_circular_region = max(regions, key=lambda r: (4 * np.pi * r.area) / (r.perimeter ** 2 + 1e-5))  \n",
    "        best_lv_centroid = most_circular_region.centroid\n",
    "        reference_lv_size = most_circular_region.area  # Store reference LV size\n",
    "        chosen_slice = i\n",
    "        break  # Take the first well-defined LV region\n",
    "\n",
    "    if best_lv_centroid is None:\n",
    "        raise ValueError(\"Could not identify a well-segmented LV region in slices 41-100.\")\n",
    "\n",
    "    # Step 2: Find the label containing this LV centroid\n",
    "    slice_labels = label(watershed_labels[chosen_slice])\n",
    "    for region in regionprops(slice_labels):\n",
    "        if min_size <= region.area <= max_size:  # Global threshold applied here\n",
    "            if region.bbox[0] <= best_lv_centroid[0] <= region.bbox[2] and \\\n",
    "               region.bbox[1] <= best_lv_centroid[1] <= region.bbox[3]:\n",
    "                best_lv_label = region.label\n",
    "                break  \n",
    "\n",
    "    if best_lv_label is None:\n",
    "        raise ValueError(\"Could not map the chosen LV centroid to a label in the reference slice.\")\n",
    "\n",
    "    # Assign LV label in the best slice\n",
    "    lv_volume[chosen_slice] = (slice_labels == best_lv_label)  \n",
    "\n",
    "    # Step 3: Use the reference LV as a mask for all slices\n",
    "    reference_mask = lv_volume[chosen_slice]  # Fixed reference LV mask\n",
    "    reference_centroid = best_lv_centroid  # Fixed reference LV centroid\n",
    "\n",
    "    for i in range(num_slices):\n",
    "        if i == chosen_slice:\n",
    "            continue  \n",
    "\n",
    "        slice_labels = label(watershed_labels[i])\n",
    "        if np.max(slice_labels) == 0:\n",
    "            continue  \n",
    "\n",
    "        # Apply global min/max size threshold\n",
    "        regions = [r for r in regionprops(slice_labels) if min_size <= r.area <= max_size]  \n",
    "        best_region = None\n",
    "        best_score = 0  # Higher is better (overlap & proximity combined)\n",
    "\n",
    "        # Step 1: Find the best region based on overlap ratio & centroid distance\n",
    "        for region in regions:\n",
    "            # Apply additional constraint only for slices **below** the reference (i.e., slices 1–41)\n",
    "            if i < chosen_slice and region.area >= 1.5 * reference_lv_size:\n",
    "                continue  # Skip regions that are 1.5x larger than the reference LV\n",
    "\n",
    "            region_mask = (slice_labels == region.label)\n",
    "            overlap = np.sum(reference_mask & region_mask)  # Count overlapping pixels\n",
    "            overlap_ratio = overlap / (region.area + 1e-5)  # Proportion of region that overlaps\n",
    "\n",
    "            # Compute centroid distance\n",
    "            centroid_x, centroid_y = region.centroid\n",
    "            distance = np.sqrt((centroid_x - reference_centroid[0]) ** 2 + (centroid_y - reference_centroid[1]) ** 2)\n",
    "\n",
    "            # Define the score: prioritize overlap but prefer closer centroids\n",
    "            score = overlap_ratio - (0.001 * distance)  # Small weight for distance\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_region = region\n",
    "\n",
    "        # Step 2: Assign the best region found\n",
    "        if best_region:\n",
    "            lv_volume[i] = (slice_labels == best_region.label)\n",
    "\n",
    "    return lv_volume\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_segmentation(volume, radius=1):\n",
    "    struct_elem = disk(radius)  # 2D circular element\n",
    "\n",
    "    cleaned_volume = np.zeros_like(volume)\n",
    "    for i in range(volume.shape[0]):\n",
    "        cleaned_slice = binary_closing(binary_opening(volume[i], struct_elem), struct_elem)\n",
    "        cleaned_volume[i] = cleaned_slice\n",
    "\n",
    "    return cleaned_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lv_metrics(lv_volumes, lv_surface_areas):\n",
    "    \"\"\"\n",
    "    Calculate important LV metrics for cardiac function assessment.\n",
    "\n",
    "    Parameters:\n",
    "    - lv_volumes: List or NumPy array of left ventricle volumes across cardiac cycle (sorted by frame).\n",
    "    - lv_surface_areas: List or NumPy array of left ventricle surface areas across the cycle.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary of LV metrics, ready for export to Excel.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert inputs to NumPy arrays if they aren't already\n",
    "    lv_volumes = np.asarray(lv_volumes)\n",
    "    lv_surface_areas = np.asarray(lv_surface_areas)\n",
    "\n",
    "    # Ensure they are 1D arrays\n",
    "    if lv_volumes.ndim != 1 or lv_surface_areas.ndim != 1:\n",
    "        raise ValueError(\"lv_volumes and lv_surface_areas must be 1D arrays.\")\n",
    "\n",
    "    # Identify end-diastolic (largest volume) and end-systolic (smallest volume) frames\n",
    "    ed_index = np.argmax(lv_volumes)  # Frame with largest volume (EDV)\n",
    "    es_index = np.argmin(lv_volumes)  # Frame with smallest volume (ESV)\n",
    "\n",
    "    edv = lv_volumes[ed_index]  # End-Diastolic Volume\n",
    "    esv = lv_volumes[es_index]  # End-Systolic Volume\n",
    "\n",
    "    # Calculate Ejection Fraction\n",
    "    ef = ((edv - esv) / edv) * 100 if edv > 0 else 0  # Avoid division by zero\n",
    "\n",
    "    # Surface areas\n",
    "    sa_ed = lv_surface_areas[ed_index]  # Surface area at ED\n",
    "    sa_es = lv_surface_areas[es_index]  # Surface area at ES\n",
    "\n",
    "    # Estimate LV diameters (approximated as width of largest cross-section)\n",
    "    lv_diameter_ed = (3 * edv / (4 * np.pi))**(1/3) * 2  # Approximated from volume\n",
    "    lv_diameter_es = (3 * esv / (4 * np.pi))**(1/3) * 2  \n",
    "\n",
    "    # Calculate sphericity index\n",
    "    sphericity_ed = lv_diameter_ed / ((6 * edv / np.pi)**(1/3)) if edv > 0 else 0\n",
    "    sphericity_es = lv_diameter_es / ((6 * esv / np.pi)**(1/3)) if esv > 0 else 0\n",
    "\n",
    "    # Store results in a dictionary\n",
    "    metrics = {\n",
    "        \"Ejection Fraction (%)\": ef,\n",
    "        \"End-Diastolic Volume (mL)\": edv,\n",
    "        \"End-Systolic Volume (mL)\": esv,\n",
    "        \"Surface Area at ED (mm²)\": sa_ed,\n",
    "        \"Surface Area at ES (mm²)\": sa_es,\n",
    "        \"LV Diameter at ED (mm)\": lv_diameter_ed,\n",
    "        \"LV Diameter at ES (mm)\": lv_diameter_es,\n",
    "        \"Sphericity Index at ED\": sphericity_ed,\n",
    "        \"Sphericity Index at ES\": sphericity_es\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_surface_marching_cubes(original_volume, segmented_volume, spacing=(10.0, 1.367188, 1.367188)):\n",
    "    \"\"\"\n",
    "    Extracts a 3D surface mesh from the original DICOM volume using Marching Cubes.\n",
    "    The segmentation mask is used as a threshold to isolate the left ventricle region.\n",
    "\n",
    "    Parameters:\n",
    "    - original_volume (ndarray): The 3D DICOM volume (slices, height, width).\n",
    "    - segmented_volume (ndarray): The 3D binary segmentation mask (LV = 1, Background = 0).\n",
    "    - spacing (tuple): (dz, dy, dx) voxel spacing for accurate scaling.\n",
    "\n",
    "    Returns:\n",
    "    - vertices (ndarray): Mesh vertices.\n",
    "    - faces (ndarray): Mesh faces (triangles).\n",
    "    \"\"\"\n",
    "    if original_volume.ndim != 3 or segmented_volume.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D input, but got shape {original_volume.shape}\")\n",
    "\n",
    "    thresholded_volume = np.where(segmented_volume > 0, original_volume, 0)\n",
    "\n",
    "    valid_pixels = thresholded_volume[thresholded_volume > 0]\n",
    "    if len(valid_pixels) == 0:\n",
    "        print(\"Warning: No valid pixels in thresholded volume. Skipping.\")\n",
    "        return None, None\n",
    "\n",
    "    level = np.percentile(valid_pixels, 50)\n",
    "\n",
    "    vertices, faces, _, _ = marching_cubes(thresholded_volume, level=level, spacing=spacing)\n",
    "    return vertices, faces\n",
    "\n",
    "def compute_lv_metrics(vertices, faces, spacing):\n",
    "    \"\"\"\n",
    "    Computes Left Ventricle volume and surface area from Marching Cubes output.\n",
    "    \n",
    "    Parameters:\n",
    "    - vertices (ndarray): Extracted 3D points from marching cubes.\n",
    "    - faces (ndarray): Triangular faces from marching cubes.\n",
    "    - spacing (tuple): Voxel spacing (dz, dy, dx) in mm.\n",
    "\n",
    "    Returns:\n",
    "    - volume (float): LV volume in milliliters (mL).\n",
    "    - surface_area (float): LV surface area in cm².\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert voxel spacing to cubic mm (scaling factor)\n",
    "    voxel_volume = spacing[0] * spacing[1] * spacing[2]  # mm³\n",
    "\n",
    "    # Compute LV Volume using Delaunay triangulation\n",
    "    tri = Delaunay(vertices)\n",
    "    volume = np.sum(np.abs(np.linalg.det(vertices[tri.simplices[:, :3]]))) / 6.0  # Volume in mm³\n",
    "    volume *= 1e-3  # Convert mm³ to mL\n",
    "\n",
    "    # Compute LV Surface Area (using skimage function)\n",
    "    surface_area = mesh_surface_area(vertices, faces) * 1e-2  # Convert mm² to cm²\n",
    "\n",
    "    return volume, surface_area\n",
    "\n",
    "def plot_3d_mesh(vertices, faces, save_path=None, patient_name = None):\n",
    "    \"\"\"\n",
    "    Plots the extracted 3D mesh using Matplotlib.\n",
    "    \"\"\"\n",
    "    if vertices is None or faces is None:\n",
    "        return\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    mesh = Poly3DCollection(vertices[faces], alpha=0.6)\n",
    "    mesh.set_edgecolor(\"k\")\n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "    ax.view_init(elev=100, azim=180) \n",
    "\n",
    "    ax.set_xlim(vertices[:, 0].min(), vertices[:, 0].max())\n",
    "    ax.set_ylim(vertices[:, 1].min(), vertices[:, 1].max())\n",
    "    ax.set_zlim(vertices[:, 2].min(), vertices[:, 2].max())\n",
    "\n",
    "    ax.set_xlabel(\"X-axis\")\n",
    "    ax.set_ylabel(\"Y-axis\")\n",
    "    ax.set_zlabel(\"Z-axis\")\n",
    "    ax.set_title(f\"Patient {patient_name} Mesh of Left Ventricle\")\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def plot_lv_metrics(lv_volumes, lv_surface_areas, num_frames=20):\n",
    "    \"\"\"\n",
    "    Plots LV Volume (mL) and LV Surface Area (cm²) over the cardiac cycle.\n",
    "\n",
    "    Parameters:\n",
    "    - lv_volumes (list): List of LV volumes over time.\n",
    "    - lv_surface_areas (list): List of LV surface areas over time.\n",
    "    - num_frames (int): Number of frames in the cardiac cycle (default: 20).\n",
    "    \"\"\"\n",
    "    time_points = np.linspace(0, 100, num_frames)  # Normalize time (0-100% cardiac cycle)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot LV Volume\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(time_points, lv_volumes, marker=\"o\", linestyle=\"-\", color=\"b\", label=\"LV Volume\")\n",
    "    plt.xlabel(\"Cardiac Cycle (%)\")\n",
    "    plt.ylabel(\"LV Volume (mL)\")\n",
    "    plt.title(\"LV Volume over Cardiac Cycle\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot LV Surface Area\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(time_points, lv_surface_areas, marker=\"s\", linestyle=\"-\", color=\"r\", label=\"LV Surface Area\")\n",
    "    plt.xlabel(\"Cardiac Cycle (%)\")\n",
    "    plt.ylabel(\"LV Surface Area (cm²)\")\n",
    "    plt.title(\"LV Surface Area over Cardiac Cycle\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_heartbeat_gif(original_volume, segmented_volume, folder_path, frames_per_slice=20):\n",
    "    \"\"\"\n",
    "    Generates a GIF of the beating heart by iterating through the cardiac cycle.\n",
    "    \n",
    "    Parameters:\n",
    "    - original_volume (ndarray): The 3D DICOM volume (frames, height, width).\n",
    "    - segmented_volume (ndarray): The 3D segmentation mask (frames, height, width).\n",
    "    - folder_path (str): Base folder where results should be saved.\n",
    "    - frames_per_slice (int): Number of frames per depth slice.\n",
    "    \"\"\"\n",
    "    # Extract folder name and create new results directory\n",
    "    base_folder_name = os.path.basename(os.path.normpath(folder_path))\n",
    "    results_folder = os.path.join(folder_path, f\"{base_folder_name}_marching_cubes_results\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    frames = []\n",
    "    temp_frame_paths = []\n",
    "    lv_volumes = []\n",
    "    lv_surface_areas = []\n",
    "\n",
    "    num_frames = frames_per_slice  # Since we have 20 unique time frames\n",
    "    slices_per_frame = original_volume.shape[0] // num_frames  # Number of spatial slices\n",
    "\n",
    "    # Loop through each time frame \n",
    "    for t in range(num_frames):\n",
    "        print(f\"Processing frame {t + 1}/{num_frames}\")\n",
    "\n",
    "        # Select every 20th slice for the current time frame\n",
    "        frame_original = original_volume[t::num_frames]  # Shape: (slices_per_frame, height, width)\n",
    "        frame_segmented = segmented_volume[t::num_frames]  # Shape: (slices_per_frame, height, width)\n",
    "\n",
    "        vertices, faces = extract_surface_marching_cubes(frame_original, frame_segmented)\n",
    "\n",
    "        if vertices is None or faces is None:\n",
    "            continue  # Skip frames with no valid segmentation\n",
    "\n",
    "        # Compute LV volume and surface area\n",
    "        volume, surface_area = compute_lv_metrics(vertices, faces, spacing)\n",
    "        lv_volumes.append(volume)\n",
    "        lv_surface_areas.append(surface_area)\n",
    "\n",
    "        frame_path = os.path.join(results_folder, f\"{base_folder_name}_frame_{t+1}.png\")\n",
    "        plot_3d_mesh(vertices, faces, save_path=frame_path, patient_name=base_folder_name)\n",
    "        temp_frame_paths.append(frame_path)\n",
    "\n",
    "    # Load images and save GIF\n",
    "    for frame_path in temp_frame_paths:\n",
    "        frames.append(imageio.v2.imread(frame_path))\n",
    "\n",
    "    save_gif_path = os.path.join(results_folder, f\"{base_folder_name}_heartbeat.gif\")\n",
    "    imageio.mimsave(save_gif_path, frames, duration=0.1)\n",
    "\n",
    "    print(f\"Saved all frames and heartbeat animation for patient {base_folder_name}\")\n",
    "        \n",
    "    return lv_volumes, lv_surface_areas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_original_size(mask, original_size, crop_size):\n",
    "    \"\"\"\n",
    "    Restores a cropped mask back to its original size by zero-padding.\n",
    "\n",
    "    Parameters:\n",
    "    - mask: Cropped binary mask (2D NumPy array).\n",
    "    - original_size: Tuple (orig_height, orig_width) of the DICOM slice.\n",
    "    - crop_size: Tuple (crop_height, crop_width) used during cropping.\n",
    "\n",
    "    Returns:\n",
    "    - Restored mask of original DICOM size.\n",
    "    \"\"\"\n",
    "    orig_height, orig_width = original_size\n",
    "    crop_height, crop_width = crop_size\n",
    "\n",
    "    # Create a blank mask with original size\n",
    "    restored_mask = np.zeros((orig_height, orig_width), dtype=np.uint8)\n",
    "\n",
    "    # Compute placement for the cropped mask\n",
    "    center_y, center_x = orig_height // 2, orig_width // 2\n",
    "    y_min = max(center_y - crop_height // 2, 0)\n",
    "    y_max = min(center_y + crop_height // 2, orig_height)\n",
    "    x_min = max(center_x - crop_width // 2, 0)\n",
    "    x_max = min(center_x + crop_width // 2, orig_width)\n",
    "\n",
    "    # Place the cropped mask inside the full-size mask\n",
    "    restored_mask[y_min:y_max, x_min:x_max] = mask\n",
    "\n",
    "    return restored_mask\n",
    "\n",
    "def normalize_dicom_image(image):\n",
    "    \"\"\"\n",
    "    Normalize DICOM image pixel values to 0-255 for correct visualization.\n",
    "\n",
    "    Parameters:\n",
    "    - image: 2D NumPy array of the DICOM slice.\n",
    "\n",
    "    Returns:\n",
    "    - Normalized image (dtype=np.uint8) for saving as PNG.\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    min_val, max_val = image.min(), image.max()\n",
    "    \n",
    "    if max_val > min_val:  # Avoid division by zero\n",
    "        image = (image - min_val) / (max_val - min_val) * 255.0\n",
    "\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "def save_slices_and_masks(cleaned_volume, dicom_files, folder_path):\n",
    "    \"\"\"\n",
    "    Saves both the original DICOM slice as a PNG and the corresponding LV mask.\n",
    "\n",
    "    Parameters:\n",
    "    - cleaned_volume: 3D NumPy array of LV masks.\n",
    "    - dicom_files: List of original DICOM objects.\n",
    "    - folder_path: Directory where DICOM files are stored (files will be saved here).\n",
    "    \"\"\"\n",
    "    # Extract original size from first DICOM slice\n",
    "    original_size = dicom_files[0].pixel_array.shape\n",
    "    crop_size = cleaned_volume[0].shape\n",
    "\n",
    "    for i, dicom_file in enumerate(dicom_files):\n",
    "        # Extract original DICOM filename (without extension)\n",
    "        dicom_filename = os.path.splitext(os.path.basename(dicom_file.filename))[0]\n",
    "\n",
    "        # Restore the mask to its original size\n",
    "        restored_mask = restore_original_size(cleaned_volume[i], original_size, crop_size)\n",
    "\n",
    "        # Normalize and save the original DICOM slice\n",
    "        original_image = normalize_dicom_image(dicom_file.pixel_array)\n",
    "        original_path = os.path.join(folder_path, f\"{dicom_filename}.png\")\n",
    "        imsave(original_path, original_image)\n",
    "\n",
    "        # Save the mask (even if empty)\n",
    "        mask_path = os.path.join(folder_path, f\"{dicom_filename}_mask_marching_cubes.png\")\n",
    "        imsave(mask_path, (restored_mask * 255).astype(np.uint8))  # Convert binary mask to 0-255\n",
    "\n",
    "        # print(f\"✅ Saved: {original_path} and {mask_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 1/20\n",
      "Processing frame 2/20\n",
      "Processing frame 3/20\n",
      "Processing frame 4/20\n",
      "Processing frame 5/20\n",
      "Processing frame 6/20\n",
      "Processing frame 7/20\n",
      "Processing frame 8/20\n",
      "Processing frame 9/20\n",
      "Processing frame 10/20\n",
      "Processing frame 11/20\n",
      "Processing frame 12/20\n",
      "Processing frame 13/20\n",
      "Processing frame 14/20\n",
      "Processing frame 15/20\n",
      "Processing frame 16/20\n",
      "Processing frame 17/20\n",
      "Processing frame 18/20\n",
      "Processing frame 19/20\n",
      "Processing frame 20/20\n",
      "Saved all frames and heartbeat animation for patient CINESAX_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0161_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0170_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0171_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0172_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0173_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0174_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0175_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0176_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0177_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0178_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0179_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0180_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0142_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0145_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0146_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0147_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0148_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0149_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0150_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0152_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0154_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0155_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0156_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0157_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Kaiwen Liu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\skimage\\_shared\\utils.py:328: UserWarning: C:\\Users\\Kaiwen Liu\\OneDrive - University of Toronto\\Desktop\\github_repo\\heart_cardiac_mri_image_processing\\data\\SCD_IMAGES_04\\SCD0003101\\CINESAX_4\\IM-0002-0129_mask_marching_cubes.png is a low contrast image\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "normalized_volume = normalize_volume(volume)\n",
    "\n",
    "# Crop the center 256x256 region\n",
    "cropped_volume = crop_center(normalized_volume, crop_size=(120, 120))\n",
    "\n",
    "# Apply center weighting\n",
    "cropped_volume = apply_center_weighting(cropped_volume, alpha=3)\n",
    "\n",
    "# Apply segmentation with border removal\n",
    "segmented_volume = segment_heart_otsu(cropped_volume)\n",
    "\n",
    "# Apply circular filtering to segmentation\n",
    "filtered_segmentation = filter_circular_regions(segmented_volume, circularity_thresh=0.15, min_size=100)\n",
    "\n",
    "# Apply watershed segmetation \n",
    "watershed_volume = improved_watershed(segmented_volume)\n",
    "\n",
    "# Isolate the left ventricle\n",
    "left_ventricle_isolation = LV_isolation(watershed_volume)\n",
    "\n",
    "# Morphological opening and closing to remove small specks and fill holes\n",
    "cleaned_volume = clean_segmentation(left_ventricle_isolation, radius=2)\n",
    "\n",
    "# Output gif of cardiac left ventricle cycle from marching cubes reconstruction and output metrics for LV quantification\n",
    "result = create_heartbeat_gif(cropped_volume, cleaned_volume, folder_path)\n",
    "if result is not None:\n",
    "    lv_volumes, lv_surface_areas = result\n",
    "else:\n",
    "    lv_volumes, lv_surface_areas = [], []\n",
    "    print(\"⚠️ Warning: create_heartbeat_gif() returned None. Using empty lists.\")\n",
    "\n",
    "# Save the masks as well as the original dicom files\n",
    "save_slices_and_masks(cleaned_volume, dicom_files, folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Patient ID': 'SCD0000101', 'Gender': ['Male'], 'Age': [53], 'Pathology': ['Heart failure with infarct'], 'Ejection Fraction (%)': np.float64(54.204209618050626), 'End-Diastolic Volume (mL)': np.float64(4962.848357758506), 'End-Systolic Volume (mL)': np.float64(2272.7756308931025), 'Surface Area at ED (mm²)': np.float64(177.96214797247106), 'Surface Area at ES (mm²)': np.float64(101.2111630397693), 'LV Diameter at ED (mm)': np.float64(21.163011162161784), 'LV Diameter at ES (mm)': np.float64(16.31245452379578), 'Sphericity Index at ED': np.float64(1.0), 'Sphericity Index at ES': np.float64(1.0)}\n",
      "['C:\\\\Users\\\\Kaiwen Liu\\\\OneDrive - University of Toronto\\\\Desktop\\\\github_repo\\\\heart_cardiac_mri_image_processing\\\\data\\\\SCD_IMAGES_01\\\\SCD0000101\\\\CINESAX_300']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{patient_information}\")\n",
    "print(f\"{patient_filepaths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Kaiwen Liu\\\\OneDrive - University of Toronto\\\\Desktop\\\\github_repo\\\\heart_cardiac_mri_image_processing\\\\data\\\\SCD_IMAGES_01\\\\SCD0000101\\\\CINESAX_300']\n",
      "Processing MRI of patient: SCD0000101\n",
      "{'Ejection Fraction (%)': np.float64(54.204209618050626), 'End-Diastolic Volume (mL)': np.float64(4962.848357758506), 'End-Systolic Volume (mL)': np.float64(2272.7756308931025), 'Surface Area at ED (mm²)': np.float64(177.96214797247106), 'Surface Area at ES (mm²)': np.float64(101.2111630397693), 'LV Diameter at ED (mm)': np.float64(21.163011162161784), 'LV Diameter at ES (mm)': np.float64(16.31245452379578), 'Sphericity Index at ED': np.float64(1.0), 'Sphericity Index at ES': np.float64(1.0)}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[167]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Check if file exists\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(patient_filepaths[\u001b[32m0\u001b[39m]):\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Load existing data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     existing_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_information\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Append new data\u001b[39;00m\n\u001b[32m     45\u001b[39m     updated_data = pd.concat([existing_data, new_data], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = engine\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[39m, in \u001b[36mOpenpyxlReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[32m    543\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    552\u001b[39m import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\excel\\_base.py:563\u001b[39m, in \u001b[36mBaseExcelReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = IOHandles(\n\u001b[32m    560\u001b[39m     handle=filepath_or_buffer, compression={\u001b[33m\"\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m    561\u001b[39m )\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[38;5;28mself\u001b[39m._workbook_class)):\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handles.handle, \u001b[38;5;28mself\u001b[39m._workbook_class):\n\u001b[32m    568\u001b[39m     \u001b[38;5;28mself\u001b[39m.book = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:472\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[32m    469\u001b[39m     \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[33m\"\u001b[39m\u001b[33mwrite\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    470\u001b[39m ):\n\u001b[32m    471\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(filepath_or_buffer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[32m    475\u001b[39m     filepath_or_buffer=filepath_or_buffer,\n\u001b[32m    476\u001b[39m     encoding=encoding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    479\u001b[39m     mode=mode,\n\u001b[32m    480\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Invalid file path or buffer object type: <class 'dict'>"
     ]
    }
   ],
   "source": [
    "xlsx_filepaths = pd.read_excel(patient_data_excel_path, sheet_name=patient_data)\n",
    "patient_ids = xlsx_filepaths['patient_id'].unique()\n",
    "metrics = calculate_lv_metrics(lv_volumes, lv_surface_areas)\n",
    "\n",
    "current_patient_idx = 0\n",
    "\n",
    "while 0 <= current_patient_idx < 2:\n",
    "\n",
    "    patient_id = patient_ids[current_patient_idx]\n",
    "    patient_filepaths = xlsx_filepaths.loc[xlsx_filepaths['patient_id']==patient_id, 'filepath'].tolist()\n",
    "\n",
    "    patient_filepaths = [os.path.join(user_handle, i) for i in sorted(patient_filepaths)]\n",
    "\n",
    "    print(f\"{patient_filepaths}\")\n",
    "    \n",
    "    patient_age = xlsx_filepaths.loc[xlsx_filepaths['patient_id']==patient_id, 'age'].tolist()\n",
    "    patient_gender = xlsx_filepaths.loc[xlsx_filepaths['patient_id']==patient_id, 'gender'].tolist()\n",
    "    patient_pathology = xlsx_filepaths.loc[xlsx_filepaths['patient_id']==patient_id, 'pathology'].tolist()\n",
    "    # frames_filepaths = xlsx_filepaths.loc[xlsx_filepaths['patient_id']==patient_id, 'dcm_image_filepath'].tolist()\n",
    "\n",
    "    print(f\"Processing MRI of patient: {patient_id}\")\n",
    "\n",
    "    # Ensure all metric values are scalar (convert lists/arrays to single values)\n",
    "    # metrics = marching_cubes_implementation(patient_filepaths[0])\n",
    "    print(f\"{metrics}\")\n",
    "    formatted_metrics = {key: (value[0] if isinstance(value, (list, tuple, np.ndarray)) else value) for key, value in metrics.items()}\n",
    "\n",
    "    # Create a single dictionary for the patient\n",
    "    patient_information = {\n",
    "        \"Patient ID\": patient_id,\n",
    "        \"Gender\": patient_gender,\n",
    "        \"Age\": patient_age,\n",
    "        \"Pathology\": patient_pathology,\n",
    "        **formatted_metrics  # Expands all the LV metrics into separate columns\n",
    "    }\n",
    "    \n",
    "    new_data = pd.DataFrame([patient_information])\n",
    "\n",
    "    # Check if file exists\n",
    "    if os.path.exists(patient_filepaths[0]):\n",
    "        # Load existing data\n",
    "        existing_data = pd.read_excel(patient_information, engine=\"openpyxl\")\n",
    "        \n",
    "        # Append new data\n",
    "        updated_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "    else:\n",
    "        updated_data = new_data\n",
    "\n",
    "    # **Safe saving** - avoid permission issues\n",
    "    temp_path = patient_filepaths + \"_tmp.xlsx\"  # Create a temp file to prevent overwrite issues\n",
    "    updated_data.to_excel(temp_path, index=False, engine=\"openpyxl\")\n",
    "\n",
    "    # Replace the old file with the new one safely\n",
    "    os.replace(temp_path, patient_filepaths)\n",
    "    \n",
    "    print(f\"✅ Patient {patient_id} data added to {patient_filepaths}\")\n",
    "\n",
    "    current_patient_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(121.08721461972031),\n",
       " np.float64(113.29461467863432),\n",
       " np.float64(105.19547248501804),\n",
       " np.float64(134.9822097508957),\n",
       " np.float64(161.5374161988815),\n",
       " np.float64(177.96214797247106),\n",
       " np.float64(160.5696975340176),\n",
       " np.float64(140.8199692885159),\n",
       " np.float64(101.2111630397693),\n",
       " np.float64(111.13841896130077),\n",
       " np.float64(126.18126779208224),\n",
       " np.float64(128.32786770146592),\n",
       " np.float64(126.82151379913387),\n",
       " np.float64(126.21095151654303),\n",
       " np.float64(128.54524398317477),\n",
       " np.float64(128.37616975032907),\n",
       " np.float64(123.20715459534749),\n",
       " np.float64(123.12859240070712),\n",
       " np.float64(123.5507817387892),\n",
       " np.float64(124.06558664466571)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv_surface_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ejection Fraction (%)': np.float64(54.204209618050626), 'End-Diastolic Volume (mL)': np.float64(4962.848357758506), 'End-Systolic Volume (mL)': np.float64(2272.7756308931025), 'Surface Area at ED (mm²)': np.float64(177.96214797247106), 'Surface Area at ES (mm²)': np.float64(101.2111630397693), 'LV Diameter at ED (mm)': np.float64(21.163011162161784), 'LV Diameter at ES (mm)': np.float64(16.31245452379578), 'Sphericity Index at ED': np.float64(1.0), 'Sphericity Index at ES': np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "metrics = calculate_lv_metrics(lv_volumes, lv_surface_areas)\n",
    "print(f\"{metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
